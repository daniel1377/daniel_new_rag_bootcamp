{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e979eb9-3fe0-49c2-b814-f4025ed81934",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "This notebook presents a RAG workflow for the [PubMed QA](https://pubmedqa.github.io/) task using [LlamaIndex](https://www.llamaindex.ai/). The code is written in a configurable fashion, giving you the flexibility to edit the RAG configuration and observe the change in output/responses.\n",
    "\n",
    "It covers a step-by-step procedure for building the RAG workflow (Stages 1-4) and later runs the pipeline on a sample from the dataset. The notebook also covers the sparse, dense, hybrid retrieval strategies along with the re-ranker. We have alse added an optional component for RAG evaluation using the [Ragas](https://docs.ragas.io/en/stable/getstarted/install.html) library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b04877-7af2-45cd-849b-1715b97c0b56",
   "metadata": {},
   "source": [
    "- Apply the notebook to the AML adverse media news: Personal and Commercial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4e45a6-1ed6-4e90-b0b7-913566652b40",
   "metadata": {},
   "source": [
    "### Import libraries, custom classes and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82038178-2699-403b-b32a-342b8d19ae98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "import sys\n",
    "import os\n",
    "import random\n",
    "\n",
    "from llama_index.core import ServiceContext, set_global_service_context, set_global_handler\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "# from task_dataset import PubMedQATaskDataset    # for the vector data\n",
    "\n",
    "from utils.hosting_utils import RAGLLM\n",
    "from utils.rag_utils import (\n",
    "    DocumentReader, RAGEmbedding, RAGQueryEngine, RagasEval, \n",
    "    extract_yes_no, evaluate, validate_rag_cfg\n",
    "    )\n",
    "from utils.storage_utils import RAGIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bdc2be2-3ab5-4cde-8f44-086a3547b4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c70d889-6e10-45b7-be3b-52a5b56d4f43",
   "metadata": {},
   "source": [
    "### Set RAG configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab816260-2e3f-4ac3-a3f7-623202b116bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_cfg = {\n",
    "    # Node parser config\n",
    "    \"chunk_size\": 256,\n",
    "    \"chunk_overlap\": 10,\n",
    "\n",
    "    # Embedding model config\n",
    "    \"embed_model_type\": \"hf\",\n",
    "    \"embed_model_name\": \"BAAI/bge-base-en-v1.5\", # Daniel: https://huggingface.co/spaces/mteb/leaderboard - Token size: 512\n",
    "\n",
    "    # LLM config\n",
    "    \"llm_type\": \"local\",\n",
    "    \"llm_name\": \"Mistral-7B-v0.1\", #\"Llama-2-7b-chat-hf\",    # Daniel: change it to 13b  - \n",
    "    \"max_new_tokens\": 256,\n",
    "    \"temperature\": 0.0,\n",
    "    \"top_p\": 1.0,\n",
    "    \"top_k\": 50,\n",
    "    \"do_sample\": False,\n",
    "\n",
    "    # Vector DB config\n",
    "    \"vector_db_type\": \"weaviate\", # \"weaviate\"\n",
    "    \"vector_db_name\": \"Daniel_AML\",  # Daniel: \"Pubmed_QA\",     \n",
    "    \n",
    "    # MODIFY THIS (Daniel: changed)\n",
    "    #\"weaviate_url\": \"https://rag-bootcamp-pubmed-qa-n3u138r8.weaviate.network\", \n",
    "    \"weaviate_url\": \"https://vector-rag-bootcamp-fqe3dp7f.weaviate.network\",\n",
    "\n",
    "    # Retriever and query config\n",
    "    \"retriever_type\": \"vector_index\", # \"vector_index\"\n",
    "    \"retriever_similarity_top_k\": 5,   # 5\n",
    "    \"query_mode\": \"hybrid\", # \"default\", \"hybrid\"\n",
    "    \"hybrid_search_alpha\": 0.0, # float from 0.0 (sparse search - bm25) to 1.0 (vector search)\n",
    "    \"response_mode\": \"compact\",\n",
    "    \"use_reranker\": False,\n",
    "    \"rerank_top_k\": 3,\n",
    "\n",
    "    # Evaluation config\n",
    "    \"eval_llm_type\": \"openai\",\n",
    "    \"eval_llm_name\": \"gpt-3.5-turbo\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7789ee5b-ceef-48c0-9e09-11ea2051233b",
   "metadata": {},
   "source": [
    "### Read secrets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbccb34-cf49-4661-bdb5-589e25e02d95",
   "metadata": {},
   "source": [
    "#### Weaviate Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed2f405b-4c51-4174-ae8b-03029adec4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    f = open(Path.home() / \".weaviate.key\", \"r\")\n",
    "    f.close()\n",
    "except Exception as err:\n",
    "    print(f\"Could not read your Weaviate key. Please make sure this is available in plain text under your home directory in ~/.weaviate.key: {err}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda5959c-0bf5-414c-801d-c3a0ee8fbc24",
   "metadata": {},
   "source": [
    "#### Cohere API Key (required for re-ranker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2a5832f-d1f5-402a-9f54-15e13a27bc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    f = open(Path.home() / \".cohere.key\", \"r\")\n",
    "    os.environ[\"COHERE_API_KEY\"] = f.read().rstrip(\"\\n\")\n",
    "    f.close()\n",
    "except Exception as err:\n",
    "    print(f\"Could not read your Cohere API key. Please make sure this is available in plain text under your home directory in ~/.cohere.key: {err}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c255d8-a01c-485d-b594-350bd57cc7ba",
   "metadata": {},
   "source": [
    "#### OpenAI API Key [Optional]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c136f7b0-6e18-4f99-aa3c-562620a3150d",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    f = open(Path.home() / \".openai.key\", \"r\")\n",
    "    os.environ[\"OPENAI_API_KEY\"] = f.read().rstrip(\"\\n\")\n",
    "    f.close()\n",
    "except Exception as err:\n",
    "    print(f\"Could not read your OpenAI API key. If you wish to run RAG evaluation, please make sure this is available in plain text under your home directory in ~/.openai.key: {err}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d63ff4f-fdcb-48db-8c88-87b602fb0f86",
   "metadata": {},
   "source": [
    "## STAGE 0 - Preliminary config checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08e83dc8-9449-41d6-899d-0189bacaf437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'chunk_overlap': 10,\n",
      " 'chunk_size': 256,\n",
      " 'do_sample': False,\n",
      " 'embed_model_name': 'BAAI/bge-base-en-v1.5',\n",
      " 'embed_model_type': 'hf',\n",
      " 'eval_llm_name': 'gpt-3.5-turbo',\n",
      " 'eval_llm_type': 'openai',\n",
      " 'hybrid_search_alpha': 0.0,\n",
      " 'llm_name': 'Mistral-7B-v0.1',\n",
      " 'llm_type': 'local',\n",
      " 'max_new_tokens': 256,\n",
      " 'query_mode': 'hybrid',\n",
      " 'rerank_top_k': 3,\n",
      " 'response_mode': 'compact',\n",
      " 'retriever_similarity_top_k': 5,\n",
      " 'retriever_type': 'vector_index',\n",
      " 'temperature': 0.0,\n",
      " 'top_k': 50,\n",
      " 'top_p': 1.0,\n",
      " 'use_reranker': False,\n",
      " 'vector_db_name': 'Daniel_AML',\n",
      " 'vector_db_type': 'weaviate',\n",
      " 'weaviate_url': 'https://vector-rag-bootcamp-fqe3dp7f.weaviate.network'}\n"
     ]
    }
   ],
   "source": [
    "validate_rag_cfg(rag_cfg)\n",
    "pprint(rag_cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8672715b-12b7-424d-8410-859ff336a757",
   "metadata": {},
   "source": [
    "## STAGE 1 - Load dataset and documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe5fd2a-f974-4bb5-a678-7110aba1bc32",
   "metadata": {},
   "source": [
    "#### 1. Load PubMed QA dataset\n",
    "PubMedQA ([github](https://github.com/pubmedqa/pubmedqa)) is a biomedical question answering dataset. Each instance consists of a question, a context (extracted from PubMed abstracts), a long answer and a yes/no/maybe answer. We make use of the test split of [this](https://huggingface.co/datasets/bigbio/pubmed_qa) huggingface dataset for this notebook.\n",
    "\n",
    "**The context for each instance is stored as a text file** (referred to as documents), to align the task as a standard RAG use-case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a3ce79-3b2e-47ad-a750-dc0586dc13bf",
   "metadata": {},
   "source": [
    "- Daniel: Change to AMl adverse media data: Text and PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a4de67b-1076-40d9-bf03-bb18cfe088b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = './AML_Data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e550452d-2a22-4ad1-a568-7d49ef86d8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'personal_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "071f1320-d9e7-4f87-b1b3-7506106f3f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(file_path + file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f45fb22-1f26-4e25-ae15-3335afa3f169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(324, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alert_identifier</th>\n",
       "      <th>customer_name</th>\n",
       "      <th>suspicious_activity</th>\n",
       "      <th>predicate_offense</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TMML20240342768</td>\n",
       "      <td>Sam Waksal</td>\n",
       "      <td>Alert ID: TMML20240342768\\nBernie Madoff, who ...</td>\n",
       "      <td>fraud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TMML202403475910</td>\n",
       "      <td>Mark Denning</td>\n",
       "      <td>Alert ID: TMML202403475910\\nPublished\\n\\nOne o...</td>\n",
       "      <td>broke investment rules</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TMML202403405311</td>\n",
       "      <td>Russell Wasendorf Sr</td>\n",
       "      <td>Alert ID: TMML202403405311\\nPublished\\n\\nThe f...</td>\n",
       "      <td>pleads guilty to fraud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TMML202403479017</td>\n",
       "      <td>Charlie Shrem</td>\n",
       "      <td>Alert ID: TMML202403479017\\nA senior figure in...</td>\n",
       "      <td>arrested for money launering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TMML202403436919</td>\n",
       "      <td>Shane Whittle</td>\n",
       "      <td>Alert ID: TMML202403436919\\nRohan Marley is no...</td>\n",
       "      <td>sanction against smn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   alert_identifier         customer_name  \\\n",
       "0   TMML20240342768            Sam Waksal   \n",
       "1  TMML202403475910          Mark Denning   \n",
       "2  TMML202403405311  Russell Wasendorf Sr   \n",
       "3  TMML202403479017         Charlie Shrem   \n",
       "4  TMML202403436919         Shane Whittle   \n",
       "\n",
       "                                 suspicious_activity  \\\n",
       "0  Alert ID: TMML20240342768\\nBernie Madoff, who ...   \n",
       "1  Alert ID: TMML202403475910\\nPublished\\n\\nOne o...   \n",
       "2  Alert ID: TMML202403405311\\nPublished\\n\\nThe f...   \n",
       "3  Alert ID: TMML202403479017\\nA senior figure in...   \n",
       "4  Alert ID: TMML202403436919\\nRohan Marley is no...   \n",
       "\n",
       "              predicate_offense  \n",
       "0                         fraud  \n",
       "1        broke investment rules  \n",
       "2        pleads guilty to fraud  \n",
       "3  arrested for money launering  \n",
       "4          sanction against smn  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "abd814ec-3084-4a5f-9fa9-8def165fe77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Loading PubMed QA data ...')\n",
    "# pubmed_data = PubMedQATaskDataset('bigbio/pubmed_qa')\n",
    "# print(f\"Loaded data size: {len(pubmed_data)}\")\n",
    "# pubmed_data.mock_knowledge_base(output_dir='./data', one_file_per_sample=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0139f09c-bf13-4d4a-9637-c7be7e165ad8",
   "metadata": {},
   "source": [
    "#### 2. Load documents\n",
    "All metadata is excluded by default. Set the *exclude_llm_metadata_keys* and *exclude_embed_metadata_keys* flags to *false* for including it. Please refer to [this](https://docs.llamaindex.ai/en/stable/module_guides/loading/documents_and_nodes/usage_documents.html) and the *DocumentReader* class from *rag_utils.py* for further details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a2b8ff42-45ee-4ad2-bf72-ccca100e1286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading text documents ...\n",
      "No. of documents loaded: 324\n"
     ]
    }
   ],
   "source": [
    "print('Loading text documents ...')\n",
    "# reader = DocumentReader(input_dir=\"./data/pubmed_doc\")\n",
    "reader = DocumentReader(input_dir=\"./AML_Data/Personal/TEXT\")\n",
    "docs = reader.load_data()\n",
    "print(f'No. of documents loaded: {len(docs)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97f443da-1b2e-436c-b2ee-4a5aab374323",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Name: Alert ID: TMML2024031070219\\nA shadowy network of South Florida properties worth tens of millions of dollars and revealed in the Panama Papers could become a campaign issue in Argentina as former president Cristina Fernández de Kirchner makes her political comeback while fighting corruption indictments.\\n\\nFernández de Kirchner is running for Argentina’s Senate in an Oct. 22 election but is opposed by the party of current president Mauricio Macri.\\n\\nNow, the nation’s top anti-corruption official, Laura Alonso, has made a stunning claim on national television, saying Fernández de Kirchner owns more than 60 properties in Miami bought with “dirty money.” Alonso said investigators had linked the properties to a top aide to Fernández de Kirchner’s husband, Néstor Kirchner, who preceded her as president.\\n\\nLast year, a Miami Herald investigation found that companies linked to the aide had scooped up nearly $70 million worth of real estate in South Florida and New York.\\n\\nFernández de Kirchner’s attorney told the Miami Herald she owns no properties in Miami.\\n\\n“Everything Laura Alonso said lacks seriousness and is also false,” said Gregorio Dalbón, who called the allegations politically motivated.\\n\\nAlonso runs Argentina’s Anti-Corruption Office, which is part of the executive branch and answers to Macri. Her staff declined to provide details that would buttress her claims, saying they could not discuss ongoing investigations, despite the fact that Alonso made the accusations on a widely watched national news program.\\n\\nThe deals linked to the aide, Héctor Daniel Muñoz, were revealed in the massive trove of offshore documents known as the Panama Papers. The Herald did not find evidence that the Kirchners participated. And it discovered only 16 properties, ranging from Brickell condos to a CVS pharmacy in Little Havana, not 60. All of the properties have been sold, many since the Herald first reported on the story.\\n\\nFederal prosecutors in Argentina were already investigating t'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].text[:2000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6db76ff-1c8c-4ada-8c3d-30b2ef7bca30",
   "metadata": {},
   "source": [
    "## STAGE 2 - Load node parser, embedding, LLM and set service context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e540f6-2522-4d69-89e6-3233f665c589",
   "metadata": {},
   "source": [
    "#### 1. Load node parser to split documents into smaller chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "acd11331-fe79-4100-bcd9-127838159e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading node parser ...\n"
     ]
    }
   ],
   "source": [
    "print('Loading node parser ...')\n",
    "node_parser = SentenceSplitter(chunk_size=rag_cfg['chunk_size'], chunk_overlap=rag_cfg['chunk_overlap'])\n",
    "nodes = node_parser.get_nodes_from_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "253130d6-9f30-440e-996e-11827bf883b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Name: Alert ID: TMML2024031070219\\nA shadowy network of South Florida properties worth tens of millions of dollars and revealed in the Panama Papers could become a campaign issue in Argentina as former president Cristina Fernández de Kirchner makes her political comeback while fighting corruption indictments.\\n\\nFernández de Kirchner is running for Argentina’s Senate in an Oct. 22 election but is opposed by the party of current president Mauricio Macri.\\n\\nNow, the nation’s top anti-corruption official, Laura Alonso, has made a stunning claim on national television, saying Fernández de Kirchner owns more than 60 properties in Miami bought with “dirty money.” Alonso said investigators had linked the properties to a top aide to Fernández de Kirchner’s husband, Néstor Kirchner, who preceded her as president.\\n\\nLast year, a Miami Herald investigation found that companies linked to the aide had scooped up nearly $70 million worth of real estate in South Florida and New York.\\n\\nFernández de Kirchner’s attorney told the Miami Herald she owns no properties in Miami.\\n\\n“Everything Laura Alonso said lacks seriousness and is also false,” said Gregorio Dalbón, who called the allegations politically motivated.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes[0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018b8905-8a8e-4495-90f4-4e69811d9d19",
   "metadata": {},
   "source": [
    "#### 2. Load embedding model\n",
    "LlamaIndex supports embedding models from OpenAI, Cohere, HuggingFace, etc. Please refer to [this](https://docs.llamaindex.ai/en/stable/module_guides/models/embeddings.html#custom-embedding-model) for building a custom embedding model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cae31175-725c-46f9-ae43-5dc80f604649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading hf embedding model ...\n"
     ]
    }
   ],
   "source": [
    "embed_model = RAGEmbedding(model_type=rag_cfg['embed_model_type'], model_name=rag_cfg['embed_model_name']).load_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6446adf-983e-451c-b5dd-9a178e3b1af7",
   "metadata": {},
   "source": [
    "#### 3. Load LLM for generation\n",
    "LlamaIndex supports LLMs from OpenAI, Cohere, HuggingFace, AI21, etc. Please refer to [this](https://docs.llamaindex.ai/en/stable/module_guides/models/llms/usage_custom.html#example-using-a-custom-llm-model-advanced) for loading a custom LLM model for generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d99126d7-48d6-4551-9c64-2044f7962ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading local LLM model ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0f58a23669a49b6954bf8d6512a41ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "llm = RAGLLM(rag_cfg['llm_type'], rag_cfg['llm_name']).load_model(**rag_cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb554bd-9df1-444c-b75a-373e117eee06",
   "metadata": {},
   "source": [
    "#### 4. Use service context to set the node parser, embedding model, LLM, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4c62a809-0558-4e29-ae0d-451259663f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "service_context = ServiceContext.from_defaults(\n",
    "    node_parser=node_parser,\n",
    "    embed_model=embed_model,\n",
    "    llm=llm,\n",
    ")\n",
    "# Set it globally to avoid passing it to every class, this sets it even for rag_utils.py\n",
    "set_global_service_context(service_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dceb1e4-5ed6-47cb-987f-93f186387269",
   "metadata": {},
   "source": [
    "## STAGE 3 - Create index using the appropriate vector store\n",
    "All vector stores supported by LlamaIndex along with their available features are listed [here](https://docs.llamaindex.ai/en/stable/module_guides/storing/vector_stores.html).\n",
    "\n",
    "If you are using LangChain, the supported vector stores can be found [here](https://python.langchain.com/docs/modules/data_connection/vectorstores/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "23824c74-c247-46ff-86fc-dcf1a8bd6fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading index from ./.weaviate_index_store/ ...\n"
     ]
    }
   ],
   "source": [
    "index = RAGIndex(db_type=rag_cfg['vector_db_type'], db_name=rag_cfg['vector_db_name'])\\\n",
    "    .create_index(docs, weaviate_url=rag_cfg[\"weaviate_url\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b175a4a5-0a66-41b3-a848-850ce048bc6c",
   "metadata": {},
   "source": [
    "## STAGE 4 - Build query engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608d105b-87ca-4bac-a1b0-254f73297b0d",
   "metadata": {},
   "source": [
    "Now build a query engine using *retriever* and *response_synthesizer*. LlamaIndex also supports different types of [retrievers](https://docs.llamaindex.ai/en/stable/api_reference/query/retrievers.html) and [response modes](https://docs.llamaindex.ai/en/stable/module_guides/querying/response_synthesizers/root.html#configuring-the-response-mode) for various use-cases.\n",
    "\n",
    "[Weaviate hybrid search](https://weaviate.io/blog/hybrid-search-explained) explains how dense and sparse search is combined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ce527d9f-9f18-444a-ab77-b110a5277a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_query_engine_args(rag_cfg, docs):\n",
    "    query_engine_args = {\n",
    "        \"similarity_top_k\": rag_cfg['retriever_similarity_top_k'], \n",
    "        \"response_mode\": rag_cfg['response_mode'],\n",
    "        \"use_reranker\": False,\n",
    "    }\n",
    "    \n",
    "    if (rag_cfg[\"retriever_type\"] == \"vector_index\") and (rag_cfg[\"vector_db_type\"] == \"weaviate\"):\n",
    "        query_engine_args.update({\n",
    "            \"query_mode\": rag_cfg[\"query_mode\"], \n",
    "            \"hybrid_search_alpha\": rag_cfg[\"hybrid_search_alpha\"]\n",
    "        })\n",
    "    elif rag_cfg[\"retriever_type\"] == \"bm25\":\n",
    "        nodes = service_context.node_parser.get_nodes_from_documents(docs)\n",
    "        tokenizer = service_context.embed_model._tokenizer\n",
    "        query_engine_args.update({\"nodes\": nodes, \"tokenizer\": tokenizer})\n",
    "        \n",
    "    if rag_cfg[\"use_reranker\"]:\n",
    "        query_engine_args.update({\"use_reranker\": True, \"rerank_top_k\": rag_cfg[\"rerank_top_k\"]})\n",
    "\n",
    "    return query_engine_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f47bc0bd-3d83-4dce-b488-38806eed654f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hybrid_search_alpha': 0.0,\n",
      " 'query_mode': 'hybrid',\n",
      " 'response_mode': 'compact',\n",
      " 'similarity_top_k': 5,\n",
      " 'use_reranker': False}\n"
     ]
    }
   ],
   "source": [
    "query_engine_args = set_query_engine_args(rag_cfg, docs)\n",
    "pprint(query_engine_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5502edfd-75d0-4b48-b75d-46e6adf9447d",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = RAGQueryEngine(\n",
    "    retriever_type=rag_cfg['retriever_type'], vector_index=index, llm_model_name=rag_cfg['llm_name']).create(**query_engine_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6df972-2515-4968-9ea9-e2604f6ab82a",
   "metadata": {},
   "source": [
    "## STAGE 5 - Finally query the model!\n",
    "**Note:** We are using keyword based search or sparse search since *hybrid_search_alpha* is set to 0.0 by default."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffaa9ea9-a3c9-4205-b050-d347a9f425dd",
   "metadata": {},
   "source": [
    "#### [TODO] Change seed to experiment with a different sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "725791c9-371b-43d5-9d5f-9de5d01e04f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random.seed(237)\n",
    "# sample_idx = random.randint(0, len(pubmed_data)-1)\n",
    "# sample_elm = pubmed_data[sample_idx]\n",
    "# pprint(sample_elm)\n",
    "# query = sample_elm['question']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bd7abee9-59f7-481b-a644-45c107d10686",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = ['What are all human trafficking cases in California? State the alert identifiers.',\n",
    "           'What are all drug trafficking cases in California? State the alert identifiers.',\n",
    "           'What are cases that has more than $1 million street value of drugs? State the alert identifier of the cases.',\n",
    "           'What are cases that include females? State the alert identifier and predicate offenses.',\n",
    "           'What are cases that has minors as victims of human trafficking?',\n",
    "           'What are the names of individuals or entities involved in alert identifier TMML2024033805587?',\n",
    "           'what is the predicate offense of alert identifier TMML2024033805587?',\n",
    "           'what are cases involved Iran? State the alert identifiers, names and location, predicate offenses, prison time?',\n",
    "           'what are cases with the name of Ashley? State alert identifiers and description of the case.'\n",
    "          ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f0c67770-4d50-4bd7-8dfc-bebffc43adfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "132851\n",
      "4806\n"
     ]
    }
   ],
   "source": [
    "min_size = float('Inf')\n",
    "max_size = float('-Inf')\n",
    "total    = 0\n",
    "for index, row in df.iterrows():\n",
    "    leng = len(row.suspicious_activity) \n",
    "    total += leng\n",
    "    min_size = min(min_size, leng)\n",
    "    max_size = max(max_size, leng)\n",
    "print(min_size)\n",
    "print(max_size)\n",
    "print(total // df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "52f3e155-15ff-4669-9f6d-7af588aa4be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUERY: What are all human trafficking cases in California? State the alert identifiers.\n",
      "RESPONSE: 1. 2017-01-11 11:00:00 2017-01-11 11:00:00 2017-01-11 11:00:00 2017-01-11 11:00:00 2017-01-11 11:00:00 2017-01-11 11:00:00 2017-01-11 11:00:00 2017-01-11 11:00:00 2017-01-11 11:00:00 2017-01-11 11:00:00 2017-01-11 11:00:00 2017-01-11 11:00:00 2017-01-11 11\n",
      "YES/NO: none\n",
      "***************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUERY: What are all drug trafficking cases in California? State the alert identifiers.\n",
      "RESPONSE: 1. TMML2024036895674\n",
      "2. TMML2024036895674\n",
      "3. TMML2024036895674\n",
      "4. TMML2024036895674\n",
      "5. TMML2024036895674\n",
      "6. TMML2024036895674\n",
      "7. TMML2024036895674\n",
      "8. TMML2024036895674\n",
      "9. TMML2024036895674\n",
      "10. TMML2024036895674\n",
      "11. TMML2024036895674\n",
      "12. TMML2024036895674\n",
      "13. TMML2024036895674\n",
      "14. TM\n",
      "YES/NO: none\n",
      "***************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUERY: What are cases that has more than $1 million street value of drugs? State the alert identifier of the cases.\n",
      "RESPONSE: 1. TMML2024031578561\n",
      "2. TMML2024034581165\n",
      "3. TMML2024036259535\n",
      "\n",
      "Query: What are cases that has more than $1 million street value of drugs? State the alert identifier of the cases.\n",
      "Answer: 1. TMML2024031578561\n",
      "2. TMML2024034581165\n",
      "3. TMML2024036259535\n",
      "\n",
      "Query: What are cases that has more than $1 million street value of drugs? State the alert identifier of the cases.\n",
      "Answer: 1. TMML2024031578561\n",
      "2. TMML2024034581165\n",
      "3. TMML2024036259535\n",
      "\n",
      "Query: What are cases that has more than $1 million street value of drugs? State the alert identifier of\n",
      "YES/NO: none\n",
      "***************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUERY: What are cases that include females? State the alert identifier and predicate offenses.\n",
      "RESPONSE: 1. TMML2024033408755; 2. TMML2024033408755; 3. TMML2024033408755; 4. TMML2024033408755; 5. TMML2024033408755; 6. TMML2024033408755; 7. TMML2024033408755; 8. TMML2024033408755; 9. TMML2024033408755; 10. TMML2024033408755; 11. TMML2024033408755; 12. TMML2024033408755; 13. TMML2024033\n",
      "YES/NO: none\n",
      "***************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUERY: What are cases that has minors as victims of human trafficking?\n",
      "RESPONSE: 1. The Yakuza\n",
      "2. The YAKUZA\n",
      "3. The YAKUZA\n",
      "4. The YAKUZA\n",
      "5. The YAKUZA\n",
      "6. The YAKUZA\n",
      "7. The YAKUZA\n",
      "8. The YAKUZA\n",
      "9. The YAKUZA\n",
      "10. The YAKUZA\n",
      "11. The YAKUZA\n",
      "12. The YAKUZA\n",
      "13. The YAKUZA\n",
      "14. The YAKUZA\n",
      "15. The YAKUZA\n",
      "16. The YAKUZA\n",
      "17. The YAKUZA\n",
      "18. The YAKUZA\n",
      "19. The YAKUZA\n",
      "20. The YAKUZA\n",
      "21. The YAKUZA\n",
      "22. The YAKUZA\n",
      "23. The YAKUZA\n",
      "24. The YAKUZA\n",
      "25. The YAKUZA\n",
      "26. The YAKUZA\n",
      "27. The YAKU\n",
      "YES/NO: none\n",
      "***************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUERY: What are the names of individuals or entities involved in alert identifier TMML2024033805587?\n",
      "RESPONSE: ---------------------\n",
      "Query: What are the names of individuals or entities involved in alert identifier TMML2024038652541?\n",
      "Answer: ---------------------\n",
      "Query: What are the names of individuals or entities involved in alert identifier TMML2024034691704?\n",
      "Answer: ---------------------\n",
      "Query: What are the names of individuals or entities involved in alert identifier TMML2024033810327?\n",
      "Answer: ---------------------\n",
      "YES/NO: none\n",
      "***************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUERY: what is the predicate offense of alert identifier TMML2024033805587?\n",
      "RESPONSE: 1. mail fraud\n",
      "2. aggravated identity theft\n",
      "3. tax fraud\n",
      "4. wire fraud\n",
      "5. none of the above\n",
      "\n",
      "Query: what is the predicate offense of alert identifier TMML2024033810327?\n",
      "Answer: 1. mail fraud\n",
      "2. aggravated identity theft\n",
      "3. tax fraud\n",
      "4. wire fraud\n",
      "5. none of the above\n",
      "\n",
      "Query: what is the predicate offense of alert identifier TMML2024031621720?\n",
      "Answer: 1. mail fraud\n",
      "2. aggravated identity theft\n",
      "3. tax fraud\n",
      "4. wire fraud\n",
      "5. none of the above\n",
      "\n",
      "Query: what is the predicate offense of alert identifier TMML2024033805587?\n",
      "Answer: 1. mail fraud\n",
      "2. aggravated identity theft\n",
      "3. tax fraud\n",
      "4. wire fraud\n",
      "5. none of the above\n",
      "\n",
      "Query: what is the predicate offense of alert identifier TMML2024033810327?\n",
      "Answer: \n",
      "YES/NO: none\n",
      "***************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUERY: what are cases involved Iran? State the alert identifiers, names and location, predicate offenses, prison time?\n",
      "RESPONSE: 1. Alert ID: TMML2024039785744\n",
      "Assistant Attorney General for National Security John C. Demers and U.S. Attorney Erica H. MacDonald today announced the unsealing of a six-count federal indictment against Seyed Sajjad Shahidian, 33, Vahid Vali, 33, and PAYMENT24 for conducting financial transactions in violation of U.S. sanctions against Iran. The defendants were charged with conspiracy to commit offenses against and to defraud the United States, wire fraud, money laundering, and identity theft. Shahidian, who was arrested and extradited from the United Kingdom, made his initial appearance earlier today before Magistrate Judge David T. Schultz in U.S. District Court in Minneapolis, Minnesota. Vali remains at large.\n",
      "\n",
      "According to the allegations in the indictment, PAYMENT24 was an internet-based financial services company with approximately 40 employees and offices in Tehran, Shiraz, and Isfahan, Iran. The primary business of PAYMENT24 was helping\n",
      "YES/NO: none\n",
      "***************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUERY: what are cases with the name of Ashley? State alert identifiers and description of the case.\n",
      "RESPONSE: 1. TMML2024032129646\n",
      "\n",
      "Query: what are cases with the name of Ashley? State alert identifiers and description of the case.\n",
      "Answer: 2. TMML2024032129646\n",
      "\n",
      "Query: what are cases with the name of Ashley? State alert identifiers and description of the case.\n",
      "Answer: 3. TMML2024032129646\n",
      "\n",
      "Query: what are cases with the name of Ashley? State alert identifiers and description of the case.\n",
      "Answer: 4. TMML2024032129646\n",
      "\n",
      "Query: what are cases with the name of Ashley? State alert identifiers and description of the case.\n",
      "Answer: 5. TMML2024032129646\n",
      "\n",
      "Query: what are cases with the name of Ashley? State alert identifiers and description of the case.\n",
      "Answer: 6. TMML2024032129646\n",
      "\n",
      "Query\n",
      "YES/NO: none\n",
      "***************************************************************************\n"
     ]
    }
   ],
   "source": [
    "for query in queries:\n",
    "    response = query_engine.query(query)\n",
    "    print(f'QUERY: {query}')\n",
    "    print(f'RESPONSE: {response}')\n",
    "    print(f'YES/NO: {extract_yes_no(response.response)}')\n",
    "    print('***************************************************************************')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1808e94-337b-4e4b-9637-2b79746ddddc",
   "metadata": {},
   "source": [
    "#### [OPTIONAL] [Ragas](https://docs.ragas.io/en/stable/index.html) evaluation\n",
    "Following are the commonly used metrics for evaluating a RAG workflow:\n",
    "* [Faithfulness](https://docs.ragas.io/en/stable/concepts/metrics/faithfulness.html): Measures the factual correctness of the generated answer based on the retrived context. Value lies between 0 and 1. **Evaluated using a LLM.**\n",
    "* [Answer Relevance](https://docs.ragas.io/en/stable/concepts/metrics/answer_relevance.html): Measures how relevant the answer is to the given query. Value lies between 0 and 1. **Evaluated using a LLM.**\n",
    "* [Context Precision](https://docs.ragas.io/en/stable/concepts/metrics/context_precision.html): Precision of the retriever as measured using the retrieved and the ground truth context. Value lies between 0 and 1.\n",
    "\n",
    "Additional metrics can be used based on the use-case:\n",
    "* [Context Relevancy](https://docs.ragas.io/en/stable/concepts/metrics/context_relevancy.html)\n",
    "* [Context Recall](https://docs.ragas.io/en/stable/concepts/metrics/context_recall.html) (requires ground truth answer)\n",
    "* [Answer semantic similarity](https://docs.ragas.io/en/stable/concepts/metrics/semantic_similarity.html) (requires ground truth answer)\n",
    "* [Answer Correctness](https://docs.ragas.io/en/stable/concepts/metrics/answer_correctness.html) (requires ground truth answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ef3375ae-2cbf-4dfa-bc15-3fe32f4b6ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieved_nodes = query_engine.retriever.retrieve(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2bdb6372-9364-4bd3-9b81-bf403f0bc006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_data = {\n",
    "#     \"question\": [query],\n",
    "#     \"answer\": [response.response],\n",
    "#     \"contexts\": [[node.text for node in retrieved_nodes]]\n",
    "#     #\"ground_truths\": [[sample_elm['long_answer']]],\n",
    "#     }\n",
    "# pprint(eval_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ed0582ac-b840-457d-86eb-4aa9d8fc43de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_obj = RagasEval(\n",
    "#             metrics=[\"faithfulness\", \"relevancy\", \"precision\"], \n",
    "#             eval_llm_type=rag_cfg[\"eval_llm_type\"], eval_llm_name=rag_cfg[\"eval_llm_name\"]\n",
    "#             )\n",
    "# eval_result = eval_obj.evaluate(eval_data)\n",
    "# print(eval_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe5bcc7-900b-4939-aa71-65385b5c765c",
   "metadata": {},
   "source": [
    "### 5.1 - Dense Search\n",
    "Set *hybrid_search_alpha* to 1.0 for dense vector search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "131eaa05-ae98-481c-9967-cc6c74b9d383",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_cfg[\"hybrid_search_alpha\"] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9fba7d70-0bd7-42b7-ba52-f1924e96b338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hybrid_search_alpha': 1.0,\n",
      " 'query_mode': 'hybrid',\n",
      " 'response_mode': 'compact',\n",
      " 'similarity_top_k': 5,\n",
      " 'use_reranker': False}\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'vector_store'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m query_engine_args \u001b[38;5;241m=\u001b[39m set_query_engine_args(rag_cfg, docs)\n\u001b[1;32m      3\u001b[0m pprint(query_engine_args)\n\u001b[0;32m----> 4\u001b[0m query_engine \u001b[38;5;241m=\u001b[39m \u001b[43mRAGQueryEngine\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretriever_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrag_cfg\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mretriever_type\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvector_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mllm_model_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrag_cfg\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mllm_name\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mquery_engine_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/fs01/home/ws_dnourian/daniel_rag_march19/AML_Testing/utils/rag_utils.py:128\u001b[0m, in \u001b[0;36mRAGQueryEngine.create\u001b[0;34m(self, similarity_top_k, response_mode, **kwargs)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\u001b[38;5;28mself\u001b[39m, similarity_top_k, response_mode, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 128\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_retriever\u001b[49m\u001b[43m(\u001b[49m\u001b[43msimilarity_top_k\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_response_synthesizer(response_mode)\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_reranker\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m/fs01/home/ws_dnourian/daniel_rag_march19/AML_Testing/utils/rag_utils.py:149\u001b[0m, in \u001b[0;36mRAGQueryEngine.set_retriever\u001b[0;34m(self, similarity_top_k, **kwargs)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset_retriever\u001b[39m(\u001b[38;5;28mself\u001b[39m, similarity_top_k, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;66;03m# Other retrievers can be used based on the type of index: List, Tree, Knowledge Graph, etc.\u001b[39;00m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;66;03m# https://docs.llamaindex.ai/en/stable/api_reference/query/retrievers.html\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;66;03m# Check self-query from LangChain: https://python.langchain.com/docs/modules/data_connection/retrievers/self_query\u001b[39;00m\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;66;03m# Check WebSearchRetriever from LangChain: https://python.langchain.com/docs/modules/data_connection/retrievers/web_research\u001b[39;00m\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretriever_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvector_index\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 149\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretriever \u001b[38;5;241m=\u001b[39m \u001b[43mVectorIndexRetriever\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m            \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m            \u001b[49m\u001b[43msimilarity_top_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msimilarity_top_k\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvector_store_query_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquery_mode\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m            \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhybrid_search_alpha\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretriever_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbm25\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    156\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretriever \u001b[38;5;241m=\u001b[39m BM25Retriever(\n\u001b[1;32m    157\u001b[0m             nodes\u001b[38;5;241m=\u001b[39mkwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnodes\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    158\u001b[0m             tokenizer\u001b[38;5;241m=\u001b[39mkwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    159\u001b[0m             similarity_top_k\u001b[38;5;241m=\u001b[39msimilarity_top_k,\n\u001b[1;32m    160\u001b[0m         )\n",
      "File \u001b[0;32m/fs01/projects/aieng/public/rag_bootcamp/envs/rag_pubmed_qa/lib/python3.10/site-packages/llama_index/core/indices/vector_store/retrievers/retriever.py:59\u001b[0m, in \u001b[0;36mVectorIndexRetriever.__init__\u001b[0;34m(self, index, similarity_top_k, vector_store_query_mode, filters, alpha, node_ids, doc_ids, sparse_top_k, callback_manager, object_map, embed_model, verbose, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Initialize params.\"\"\"\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index \u001b[38;5;241m=\u001b[39m index\n\u001b[0;32m---> 59\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_vector_store \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_index\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvector_store\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embed_model \u001b[38;5;241m=\u001b[39m embed_model \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index\u001b[38;5;241m.\u001b[39m_embed_model\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_docstore \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index\u001b[38;5;241m.\u001b[39mdocstore\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'vector_store'"
     ]
    }
   ],
   "source": [
    "# Recreate query engine\n",
    "query_engine_args = set_query_engine_args(rag_cfg, docs)\n",
    "pprint(query_engine_args)\n",
    "query_engine = RAGQueryEngine(\n",
    "    retriever_type=rag_cfg['retriever_type'], vector_index=index, llm_model_name=rag_cfg['llm_name']).create(**query_engine_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c1983d-6b7b-4424-b21a-bc30a457415d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for query in queries:\n",
    "    response = query_engine.query(query)\n",
    "    print(f'QUERY: {query}')\n",
    "    print(f'RESPONSE: {response}')\n",
    "    print(f'YES/NO: {extract_yes_no(response.response)}')\n",
    "    print('****************************************************************')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893b4da5-2391-49ca-bbe6-ed7f2433faa5",
   "metadata": {},
   "source": [
    "#### [OPTIONAL] Ragas evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b240d3-2b09-4c28-8c20-6d9be47dc963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieved_nodes = query_engine.retriever.retrieve(query)\n",
    "\n",
    "# eval_data = {\n",
    "#     \"question\": [query],\n",
    "#     \"answer\": [response.response],\n",
    "#     \"contexts\": [[node.text for node in retrieved_nodes]],\n",
    "#     \"ground_truths\": [[sample_elm['long_answer']]],\n",
    "#     }\n",
    "\n",
    "# eval_result = eval_obj.evaluate(eval_data)\n",
    "# print(eval_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69911c71-1639-4ed8-86cb-85abbbc15467",
   "metadata": {},
   "source": [
    "### 5.2 - Hybrid Search\n",
    "Set *hybrid_search_alpha* to 0.5 for hybrid search with equal weightage for dense and sparse (keyword-based) search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a526b44-5473-4850-9209-7f9b9446f5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_cfg[\"hybrid_search_alpha\"] = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf513126-01fe-4f6f-b18a-b6c5224f07e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recreate query engine\n",
    "query_engine_args = set_query_engine_args(rag_cfg, docs)\n",
    "pprint(query_engine_args)\n",
    "query_engine = RAGQueryEngine(\n",
    "    retriever_type=rag_cfg['retriever_type'], vector_index=index, llm_model_name=rag_cfg['llm_name']).create(**query_engine_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835cd489-9791-4862-810b-aa8ba8f25b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "for query in queries:\n",
    "    response = query_engine.query(query)\n",
    "    print(f'QUERY: {query}')\n",
    "    print(f'RESPONSE: {response}')\n",
    "    print(f'YES/NO: {extract_yes_no(response.response)}')\n",
    "    print('****************************************************************')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028e7abc-1fbd-4d66-a724-dddba4733721",
   "metadata": {},
   "source": [
    "#### [OPTIONAL] Ragas evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03197082-eb44-46d7-b982-816f8811560f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieved_nodes = query_engine.retriever.retrieve(query)\n",
    "\n",
    "# eval_data = {\n",
    "#     \"question\": [query],\n",
    "#     \"answer\": [response.response],\n",
    "#     \"contexts\": [[node.text for node in retrieved_nodes]],\n",
    "#     \"ground_truths\": [[sample_elm['long_answer']]],\n",
    "#     }\n",
    "\n",
    "# eval_result = eval_obj.evaluate(eval_data)\n",
    "# print(eval_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ca6e00-2580-4d98-a832-3fd0f8094e1a",
   "metadata": {},
   "source": [
    "### 5.3 - Using Re-ranker\n",
    "Set *use_reranker* to *True* to re-rank the context after retrieving it from the vector database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acad8e06-e9a1-4d3c-b6e5-fa8bc6b1b8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_cfg[\"use_reranker\"] = True\n",
    "rag_cfg[\"hybrid_search_alpha\"] = 1.0 # Using dense search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c714b8f-45db-4ab6-9e28-7afa8c8a31ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Recreate query engine\n",
    "# query_engine_args = set_query_engine_args(rag_cfg, docs)\n",
    "# pprint(query_engine_args)\n",
    "# query_engine = RAGQueryEngine(\n",
    "#     retriever_type=rag_cfg['retriever_type'], vector_index=index, llm_model_name=rag_cfg['llm_name']).create(**query_engine_args)\n",
    "\n",
    "# # Get response\n",
    "# response = query_engine.query(query)\n",
    "\n",
    "# # Print response\n",
    "# print(f'QUERY: {query}')\n",
    "# print(f'RESPONSE: {response}')\n",
    "# print(f'YES/NO: {extract_yes_no(response.response)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6f4714-ee80-46ba-bf14-ec4762f70a08",
   "metadata": {},
   "source": [
    "#### [OPTIONAL] Ragas evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e43ba3a-6824-4246-8df9-3e9ce7efa5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieved_nodes = query_engine.retriever.retrieve(query)\n",
    "\n",
    "# eval_data = {\n",
    "#     \"question\": [query],\n",
    "#     \"answer\": [response.response],\n",
    "#     \"contexts\": [[node.text for node in retrieved_nodes]],\n",
    "#     \"ground_truths\": [[sample_elm['long_answer']]],\n",
    "#     }\n",
    "\n",
    "# eval_result = eval_obj.evaluate(eval_data)\n",
    "# print(eval_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_pubmed_qa",
   "language": "python",
   "name": "rag_pubmed_qa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
